{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BuradsakonPongtippitak/PCA/blob/main/Python_Tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Python Tools for FTIR Microplastic Analysis Software\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### I. Data Loading & Management Tools\n",
        "\n",
        "1.  **`ftir_loader.py`**\n",
        "    * **Purpose:** Robustly load various FTIR spectral file formats.\n",
        "    * **Functionality:**\n",
        "        * `load_omnic(filepath)`: Loads .spa files (Thermo Fisher Scientific OMNIC).\n",
        "        * `load_nicolet(filepath)`: Loads .dpt files (Nicolet/Thermo Fisher).\n",
        "        * `load_jdx(filepath)`: Loads JCAMP-DX (.jdx, .dx) files (common standard).\n",
        "        * `load_csv(filepath, sep=',', header=True)`: Loads simple CSV files (assuming wavenumber in first column, absorbance/transmittance in second).\n",
        "        * `load_folder(folder_path, file_extension)`: Iterates and loads all spectra from a specified folder.\n",
        "    * **Dependencies:** `numpy`, `pandas`, `specio` (for .spa, .dpt, .jdx â€“ highly recommended for spectroscopy files).\n",
        "    * **Output:** Pandas DataFrame with wavenumbers as index and sample names as columns, or a list of `Spectrum` objects (if using a specialized library like `specio`).\n",
        "\n",
        "2.  **`spectral_dataset.py`**\n",
        "    * **Purpose:** A class to manage multiple loaded spectra, their metadata, and associated labels.\n",
        "    * **Functionality:**\n",
        "        * `add_spectrum(spectrum_data, metadata, label)`: Adds a single spectrum.\n",
        "        * `add_spectra_from_loader(loader_output)`: Integrates output from `ftir_loader`.\n",
        "        * `get_X()`: Returns spectral data (absorbance/transmittance) as a NumPy array (features for ML).\n",
        "        * `get_y()`: Returns labels (e.g., polymer type) as a NumPy array.\n",
        "        * `get_wavenumbers()`: Returns the common wavenumber axis.\n",
        "        * `filter_by_label(label_list)`: Selects subsets of data.\n",
        "        * `split_train_test(test_size=0.2, random_state=None)`: Splits data for ML.\n",
        "    * **Dependencies:** `numpy`, `pandas`.\n",
        "\n",
        "---\n",
        "\n",
        "### II. Preprocessing Tools (`ftir_preprocessor.py`)\n",
        "\n",
        "This module will contain functions for each preprocessing step, designed to be chained together.\n",
        "\n",
        "1.  **`correct_baseline(spectrum_data, method='als', poly_order=3, lam=10e5, p=0.01)`**\n",
        "    * **Methods:**\n",
        "        * `'als'`: Asymmetric Least Squares (recommended for robustness). Parameters: `lam` (smoothness), `p` (asymmetry).\n",
        "        * `'poly'`: Polynomial fitting. Parameter: `poly_order`.\n",
        "        * `'minmax'`: Simple min-max baseline (finding local minima).\n",
        "    * **Dependencies:** `scipy.signal` (for some polynomial fits), custom ALS implementation.\n",
        "\n",
        "2.  **`smooth_spectrum(spectrum_data, window_length=11, poly_order=3)`**\n",
        "    * **Method:** Savitzky-Golay filter.\n",
        "    * **Dependencies:** `scipy.signal.savgol_filter`.\n",
        "\n",
        "3.  **`normalize_spectrum(spectrum_data, method='vector')`**\n",
        "    * **Methods:**\n",
        "        * `'minmax'`: Scales to [0, 1].\n",
        "        * `'vector'`: Divides by L2 norm (unit vector normalization).\n",
        "        * `'snv'`: Standard Normal Variate (mean 0, std 1).\n",
        "        * `'msc'`: Multiplicative Signal Correction (requires a reference spectrum, or calculated mean).\n",
        "    * **Dependencies:** `numpy`.\n",
        "\n",
        "4.  **`apply_derivative(spectrum_data, order=1, window_length=11, poly_order=3)`**\n",
        "    * **Methods:** First and Second derivative using Savitzky-Golay.\n",
        "    * **Dependencies:** `scipy.signal.savgol_filter` (with `deriv=True`).\n",
        "\n",
        "5.  **`apply_atr_correction(spectrum_data, wavenumbers, atr_crystal_ri=2.4, sample_ri=1.5)`**\n",
        "    * **Purpose:** Corrects for varying penetration depth in ATR.\n",
        "    * **Dependencies:** `numpy`. Requires physical constants.\n",
        "\n",
        "6.  **`remove_membrane_filter(spectrum_data, filter_spectrum_ref, method='subtract')`**\n",
        "    * **Methods:**\n",
        "        * `'subtract'`: Simple subtraction after scaling.\n",
        "        * `'ridge'`: Ridge regression-based removal (more robust, requires a set of filter spectra and sample spectra for training).\n",
        "    * **Dependencies:** `numpy`, `scipy.optimize` (for optimization in scaling subtraction), `sklearn.linear_model` (for ridge).\n",
        "\n",
        "---\n",
        "\n",
        "### III. Machine Learning Tools (`ftir_ml_models.py`)\n",
        "\n",
        "This module will house the ML model definitions and training/prediction functionalities.\n",
        "\n",
        "1.  **`PolymerClassifier` Class**\n",
        "    * **Purpose:** Encapsulates various classification algorithms for polymer identification.\n",
        "    * **Initialization:** `__init__(model_type='svm', **model_params)`\n",
        "        * `model_type`: 'svm', 'random_forest', 'knn', 'mlp', 'cnn' (basic).\n",
        "        * `model_params`: Dictionary of hyperparameters for the chosen model.\n",
        "    * **Functionality:**\n",
        "        * `train(X_train, y_train)`: Trains the selected ML model.\n",
        "        * `predict(X_test)`: Predicts labels for new spectra.\n",
        "        * `predict_proba(X_test)`: (If applicable) Returns probability estimates for each class.\n",
        "        * `evaluate(X_test, y_test)`: Calculates common metrics (accuracy, precision, recall, F1-score, confusion matrix).\n",
        "        * `save_model(filepath)`: Saves the trained model using `joblib` or `pickle`.\n",
        "        * `load_model(filepath)`: Loads a pre-trained model.\n",
        "    * **Dependencies:** `scikit-learn` (for SVM, RF, KNN, MLP, metrics), `tensorflow` or `pytorch` (for CNN if implemented).\n",
        "\n",
        "2.  **`DimensionalityReducer` Class**\n",
        "    * **Purpose:** For reducing the number of features (wavenumbers).\n",
        "    * **Initialization:** `__init__(method='pca', n_components=0.95)`\n",
        "        * `method`: 'pca', 'tsne' (for visualization mostly), 'umap'.\n",
        "        * `n_components`: Number of components or explained variance ratio for PCA.\n",
        "    * **Functionality:**\n",
        "        * `fit(X_data)`: Fits the reducer to the data.\n",
        "        * `transform(X_data)`: Transforms data to lower dimension.\n",
        "        * `fit_transform(X_data)`: Fits and transforms.\n",
        "    * **Dependencies:** `scikit-learn.decomposition` (for PCA), `sklearn.manifold` (for t-SNE), `umap-learn` (for UMAP).\n",
        "\n",
        "3.  **`FeatureSelector` Class (Optional, for more advanced scenarios)**\n",
        "    * **Purpose:** Selects the most informative wavenumbers.\n",
        "    * **Initialization:** `__init__(method='rfe', estimator=RandomForestClassifier())`\n",
        "        * `method`: 'rfe' (Recursive Feature Elimination), 'select_from_model' (using feature importances).\n",
        "    * **Functionality:**\n",
        "        * `fit(X, y)`: Identifies relevant features.\n",
        "        * `transform(X)`: Selects only the identified features.\n",
        "    * **Dependencies:** `scikit-learn.feature_selection`.\n",
        "\n",
        "---\n",
        "\n",
        "### IV. Visualization Tools (`ftir_visualizer.py`)\n",
        "\n",
        "1.  **`plot_spectrum(wavenumbers, absorbance, title='FTIR Spectrum', label=None, show_peaks=False, peak_indices=None, filename=None)`**\n",
        "    * **Purpose:** Plot single or multiple spectra.\n",
        "    * **Functionality:**\n",
        "        * Plots absorbance vs. wavenumber.\n",
        "        * Supports overlaying multiple spectra.\n",
        "        * Optionally highlights identified peaks.\n",
        "        * Saves plot to file.\n",
        "    * **Dependencies:** `matplotlib.pyplot`.\n",
        "\n",
        "2.  **`plot_pca_results(pca_model, X_transformed, y_labels, title='PCA of FTIR Spectra', filename=None)`**\n",
        "    * **Purpose:** Visualize results of PCA (or other dimensionality reduction).\n",
        "    * **Functionality:**\n",
        "        * Plots 2D or 3D scatter plots of principal components, colored by polymer type.\n",
        "        * Plots explained variance ratio.\n",
        "    * **Dependencies:** `matplotlib.pyplot`, `seaborn` (for nicer aesthetics).\n",
        "\n",
        "3.  **`plot_confusion_matrix(y_true, y_pred, labels, title='Confusion Matrix', filename=None)`**\n",
        "    * **Purpose:** Visualize classification model performance.\n",
        "    * **Functionality:**\n",
        "        * Generates a heatmap of the confusion matrix.\n",
        "    * **Dependencies:** `matplotlib.pyplot`, `seaborn`, `sklearn.metrics.confusion_matrix`.\n",
        "\n",
        "---\n",
        "\n",
        "### V. Spectral Library & Matching Tools (`spectral_library.py`)\n",
        "\n",
        "1.  **`SpectralLibrary` Class**\n",
        "    * **Purpose:** Stores and manages a collection of reference FTIR spectra (polymers, contaminants, etc.).\n",
        "    * **Functionality:**\n",
        "        * `add_reference(spectrum_data, metadata)`: Adds a new reference spectrum.\n",
        "        * `load_from_csv(filepath)`: Loads a library from a structured CSV.\n",
        "        * `search_by_name(polymer_name)`: Retrieves spectra by name.\n",
        "        * `match_spectrum(query_spectrum, wavenumbers, method='correlation')`\n",
        "            * **Methods:**\n",
        "                * `'correlation'`: Pearson correlation coefficient (most common).\n",
        "                * `'euclidean'`: Euclidean distance.\n",
        "                * `'spectral_angle'`: Cosine similarity.\n",
        "            * Returns ordered list of best matches (polymer name, similarity score).\n",
        "    * **Dependencies:** `numpy`, `pandas`, `scipy.spatial.distance`.\n",
        "\n",
        "---\n",
        "\n",
        "### VI. Main Application Logic (`main_app.py` or `gui.py`)\n",
        "\n",
        "This would orchestrate the use of all the above modules.\n",
        "\n",
        "* **User Interface:** Could be a command-line interface (CLI) for simple scripts or a graphical user interface (GUI) using libraries like `PyQt5`, `Tkinter`, or `Streamlit` (for web-based dashboards).\n",
        "* **Workflow:**\n",
        "    1.  Load raw spectra using `ftir_loader`.\n",
        "    2.  Manage data with `spectral_dataset`.\n",
        "    3.  Apply selected preprocessing steps using `ftir_preprocessor` (e.g., `preprocess_pipeline = Pipeline([('baseline', corrector), ('smooth', smoother), ('normalize', normalizer)])`).\n",
        "    4.  Train or load `PolymerClassifier` using the preprocessed data.\n",
        "    5.  Perform predictions on unknown samples.\n",
        "    6.  Match spectra against `SpectralLibrary`.\n",
        "    7.  Visualize results using `ftir_visualizer`.\n",
        "\n",
        "---\n",
        "\n",
        "**Example of a simple workflow using these tools:**"
      ],
      "metadata": {
        "id": "-WNYSLP2qMjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have the modules designed above\n",
        "\n",
        "import os\n",
        "from ftir_loader import FTIRLoader\n",
        "from spectral_dataset import SpectralDataset\n",
        "from ftir_preprocessor import Preprocessor\n",
        "from ftir_ml_models import PolymerClassifier, DimensionalityReducer\n",
        "from ftir_visualizer import plot_spectrum, plot_pca_results, plot_confusion_matrix\n",
        "from spectral_library import SpectralLibrary\n",
        "\n",
        "# --- 1. Load Data ---\n",
        "loader = FTIRLoader()\n",
        "spectra_raw_list = loader.load_folder('data/raw_spectra', '.spa') # Or your specific format\n",
        "\n",
        "dataset = SpectralDataset()\n",
        "for spec_data, metadata, label in spectra_raw_list: # Assuming your loader returns these\n",
        "    dataset.add_spectrum(spec_data, metadata, label)\n",
        "\n",
        "X_raw = dataset.get_X()\n",
        "y_labels = dataset.get_y()\n",
        "wavenumbers = dataset.get_wavenumbers()\n",
        "\n",
        "# --- 2. Preprocess Data ---\n",
        "preprocessor = Preprocessor()\n",
        "# Define a preprocessing pipeline\n",
        "X_baseline_corrected = preprocessor.correct_baseline(X_raw)\n",
        "X_smoothed = preprocessor.smooth_spectrum(X_baseline_corrected)\n",
        "X_normalized = preprocessor.normalize_spectrum(X_smoothed, method='snv')\n",
        "\n",
        "X_processed = X_normalized # Final preprocessed data for ML\n",
        "\n",
        "# --- 3. Train ML Model ---\n",
        "X_train, X_test, y_train, y_test = dataset.split_train_test(X=X_processed, y=y_labels)\n",
        "\n",
        "classifier = PolymerClassifier(model_type='svm', C=10) # Example: SVM with C=10\n",
        "classifier.train(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "classifier.evaluate(X_test, y_test)\n",
        "plot_confusion_matrix(y_test, y_pred, labels=dataset.unique_labels) # Assuming unique_labels attribute\n",
        "\n",
        "# --- 4. Dimensionality Reduction & Visualization ---\n",
        "reducer = DimensionalityReducer(method='pca', n_components=2)\n",
        "X_pca = reducer.fit_transform(X_processed)\n",
        "plot_pca_results(reducer.pca_model, X_pca, y_labels, title='PCA of Processed Spectra')\n",
        "\n",
        "# --- 5. Spectral Library Matching (Example for a single unknown spectrum) ---\n",
        "library = SpectralLibrary()\n",
        "# Assume you have a way to populate your library (e.g., from CSV or another folder)\n",
        "# library.load_from_csv('data/reference_library.csv')\n",
        "\n",
        "unknown_spectrum_data = X_test[0] # Take one spectrum from test set as unknown\n",
        "best_match = library.match_spectrum(unknown_spectrum_data, wavenumbers)\n",
        "print(f\"Unknown spectrum best match: {best_match[0]['polymer_name']} with score {best_match[0]['score']:.2f}\")\n",
        "\n",
        "# Plotting example for a single spectrum\n",
        "plot_spectrum(wavenumbers, unknown_spectrum_data, title='Preprocessed Unknown Spectrum', label='Unknown Sample')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "igV-cbe5qMj3"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}